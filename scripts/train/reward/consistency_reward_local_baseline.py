# -*- coding: utf-8 -*-
"""
Generative Consistency Reward Plugin for GRPO
This module acts as the client side of the Generative Reward Server.
It queries a local LLM API (hosting a Referee model) to read an agent's <think> 
process. If the Referee naturally derives the exact same answer as the agent from 
that reasoning chain, the agent receives a reward of 1.0 (Logical Consistency), 
otherwise 0.0.
"""

import logging
import re
import time
from typing import List

import requests
from swift.plugin import ORM, orms

# ==========================================
# Logging Configuration
# ==========================================
log = logging.getLogger(__name__)

# ==========================================
# Local API Client with Retry Mechanism
# ==========================================
class LocalAPIClient:
    """Robust HTTP client for communicating with the local FastAPI Referee Server."""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.api_endpoint = f"{base_url}/v1/chat/completions"
        self.health_endpoint = f"{base_url}/health"
        self._check_api_available()

    def _check_api_available(self):
        """Verifies if the Referee server is online before starting training."""
        try:
            response = requests.get(self.health_endpoint, timeout=5)
            if response.status_code == 200:
                log.info(f"✅ Referee API Service is online at {self.base_url}")
            else:
                log.warning(f"⚠️ Referee API returned unexpected status: {response.status_code}")
        except requests.RequestException as e:
            log.error(f"❌ Cannot connect to Referee API: {e}")
            log.error("Make sure the reward server is running on the target GPU.")

    def generate_completion(
        self, 
        prompt: str, 
        system_prompt: str = "You are a pragmatic log analyst.", 
        max_tokens: int = 10, 
        temperature: float = 0.1,
        max_retries: int = 3
    ) -> str:
        """
        Queries the Referee model. Includes exponential backoff retries to survive 
        temporary server overloads during heavy GRPO batch processing.
        """
        request_data = {
            "model": "referee-model", 
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            "temperature": temperature,
            "max_tokens": max_tokens
        }

        for attempt in range(max_retries):
            try:
                response = requests.post(self.api_endpoint, json=request_data, timeout=30)
                if response.status_code == 200:
                    result = response.json()
                    if "choices" in result and len(result["choices"]) > 0:
                        return result["choices"][0]["message"]["content"]
                
                log.debug(f"[API Attempt {attempt+1}] Failed. Status: {response.status_code}")
            except Exception as e:
                log.debug(f"[API Attempt {attempt+1}] Exception: {e}")
            
            time.sleep(2 ** attempt) # Exponential backoff: 1s, 2s, 4s...

        log.error("❌ Referee API request failed after maximum retries.")
        return ""

# ==========================================
# Core Reward Function Plugin
# ==========================================
class ConsistencyReward(ORM):
    """
    Evaluates whether the student model's final answer logically follows from its 
    own reasoning process. It extracts the <think> block, feeds it to an independent 
    Referee model, and checks if the Referee arrives at the same conclusion.
    """

    BOXED_PATTERN = r"\$\\boxed\{([A-H])\}\$"
    ANSWER_PATTERN = r"answer\s+([A-H])\.?"
    SIMPLE_DOT_PATTERN = r"(?:^|[^A-Za-z])([A-H])\s*\."
    SIMPLE_PATTERN = r"(?:^|[^A-Za-z])([A-H])(?:$|[^A-Za-z])"
    VALID_OPTIONS = set('ABCDEFGH')

    def __init__(self, api_url: str = "http://localhost:8000"):
        super().__init__()
        self.api_client = LocalAPIClient(api_url)
        log.info("Initialized Generative Consistency Reward Plugin.")

    @staticmethod
    def extract_question(text: str) -> str:
        """Heuristically extracts the core question from complex prompt formats."""
        if not text: return ""
        
        if "Question:" in text:
            return "Question:" + text.split("Question:")[-1].strip()

        options_pattern = r"(.*?)\s*([A-D]\s*\.\s*.*?)\s*([A-D]\s*\.\s*.*?)\s*([A-D]\s*\.\s*.*?)\s*([A-D]\s*\.\s*.*?)"
        match = re.search(options_pattern, text, re.DOTALL)
        if match: return match.group(0).strip()

        return text.strip()

    @staticmethod
    def extract_think_content(text: str) -> str:
        """Isolates the reasoning chain generated by the student policy."""
        if not text: return ""
        match = re.search(r"<think>(.*?)</think>", text, re.DOTALL | re.IGNORECASE)
        if match: return match.group(1).strip()
        return ""

    def normalize_answer(self, answer: str) -> str:
        """Robustly extracts the final alphabetical choice from text."""
        answer = str(answer).strip()

        boxed_matches = list(re.finditer(self.BOXED_PATTERN, answer, re.IGNORECASE))
        if boxed_matches: return boxed_matches[-1].group(1).upper()

        answer_matches = list(re.finditer(self.ANSWER_PATTERN, answer, re.IGNORECASE))
        if answer_matches: return answer_matches[0].group(1).upper()

        dot_matches = list(re.finditer(self.SIMPLE_DOT_PATTERN, answer, re.IGNORECASE))
        if dot_matches: return dot_matches[-1].group(1).upper()

        simple_matches = list(re.finditer(self.SIMPLE_PATTERN, answer, re.IGNORECASE))
        if simple_matches: return simple_matches[-1].group(1).upper()

        match = re.search(r"<answer>(.*?)</answer>", answer, re.DOTALL | re.IGNORECASE)
        if match: return self.normalize_answer(match.group(1).strip())

        return answer.upper()

    def call_referee_for_inference(self, question: str, think_content: str) -> str:
        """
        Formulates the prompt forcing the Referee to play 'Logic Grader' based 
        exclusively on the student's thought process.
        """
        if not question or not think_content:
            return ""

        prompt = (
            "This is a multiple-choice question. Based on the following question and the provided thinking process, "
            "determine the most appropriate option (A-H) that logically follows from the thinking process.\n\n"
            "Do not analyze whether the logic is factually correct. Your ONLY task is to output the final letter "
            "that this specific thinking process points to.\n\n"
            f"[Question Context]:\n{question}\n\n"
            f"[Student's Thinking Process]:\n{think_content}\n\n"
            "Output strictly a single letter (A-H):"
        )

        referee_raw_response = self.api_client.generate_completion(
            prompt=prompt,
            system_prompt="You are a strict logic evaluator.",
            max_tokens=5,
            temperature=0.01
        )

        if referee_raw_response:
            return self.normalize_answer(referee_raw_response)
        
        return ""

    def __call__(self, completions: List[str], solution: List[str] = None, **kwargs) -> List[float]:
        """
        The main hook executed by ms-swift during GRPO rollouts.
        Assigns a reward of 1.0 if the Referee derives the same answer as the Student.
        """
        rewards = []

        if not isinstance(completions, list): completions = [completions]
        if solution is not None and not isinstance(solution, list): solution = [solution] * len(completions)

        # Robust extraction of the raw question string from ms-swift kwargs
        question_field = None
        if 'messages' in kwargs and kwargs['messages']:
            messages = kwargs['messages']
            if isinstance(messages, list) and all(isinstance(item, list) for item in messages):
                question_field = []
                for msg_list in messages:
                    for msg in msg_list:
                        if isinstance(msg, dict) and msg.get('role') == 'user':
                            question_field.append(msg.get('content', ""))
            elif isinstance(messages, list):
                for msg in messages:
                    if isinstance(msg, dict) and msg.get('role') == 'user':
                        question_field = msg.get('content', "")

        if question_field is None:
            for field in ['question', 'query', 'prompt', 'input', 'text']:
                if field in kwargs and kwargs[field]:
                    question_field = kwargs[field]
                    break

        for i, completion in enumerate(completions):
            try:
                # 1. Prerequisite: Extract the student's reasoning chain
                think_content = self.extract_think_content(completion)
                if not think_content:
                    log.debug(f"Sample {i}: Missing <think> block. Reward: 0.0")
                    rewards.append(0.0)
                    continue

                student_final_ans = self.normalize_answer(completion)

                # 2. Prerequisite: The student must be objectively correct to get consistency points
                if solution is not None:
                    sol = solution[i] if i < len(solution) else solution[-1]
                    norm_sol = self.normalize_answer(sol)

                    if student_final_ans != norm_sol:
                        log.debug(f"Sample {i}: Incorrect objective answer ({student_final_ans} != {norm_sol}). Reward: 0.0")
                        rewards.append(0.0)
                        continue

                # 3. Formulate the question context
                ques = ""
                if isinstance(question_field, list) and i < len(question_field):
                    ques = question_field[i]
                elif isinstance(question_field, str):
                    ques = question_field

                question_context = self.extract_question(ques) if ques else self.extract_question(completion)
                
                if not question_context:
                    log.warning(f"Sample {i}: Could not extract question context. Reward: 0.0")
                    rewards.append(0.0)
                    continue

                # 4. Arbitration: Query the independent Referee
                referee_ans = self.call_referee_for_inference(question_context, think_content)

                # 5. Verdict
                if referee_ans and referee_ans in self.VALID_OPTIONS:
                    if referee_ans == student_final_ans:
                        log.debug(f"Sample {i} Consistency Match: Referee({referee_ans}) == Student({student_final_ans}) -> Reward: 1.0")
                        rewards.append(1.0)
                    else:
                        log.debug(f"Sample {i} Consistency Mismatch: Referee({referee_ans}) != Student({student_final_ans}) -> Reward: 0.0")
                        rewards.append(0.0)
                else:
                    log.debug(f"Sample {i}: Referee failed to produce a valid response. Reward: 0.0")
                    rewards.append(0.0)

            except Exception as e:
                log.error(f"Error evaluating sample {i}: {e}")
                rewards.append(0.0)

        return rewards

# Register the plugin with the ms-swift ORM framework
orms['logical_consistency'] = ConsistencyReward